{
  "hash": "394f0bea43915e0dab0acb1fb35693fd",
  "result": {
    "markdown": "---\ndraft: false\ntitle: Introduction to Time Series\nauthor: Stefan Eng\ndate: '2019-07-06'\nslug: introduction-to-time-series\ncategories:\n  - statistics\ntags:\n  - R\n  - time-series\noutput:\n  blogdown::html_page:\n    toc: yes\n    fig_width: 5\n    fig_height: 5\n---\n\n::: {.cell}\n\n:::\n\n\n## Classical decomposition model\n$$\nX_t = m_t + s_t + y_y\n$$\nwhere\n  - $m : \\mathbb{Z} \\rightarrow \\mathbb{R}$ is a slowly changing function, the trend component.\n  - $s : \\mathbb Z \\rightarrow \\mathbb R$ is a function with a known period $d$, i.e., $s_{t + d} = s_t$ for all $t \\in \\mathbb Z$ and $\\sum_{j = 1}^d s_j = 0$, is called the seasonal component.\n  - $(y_t, t \\in \\mathbb Z)$ is a stationary stochastic process.\n\n## Time Series Analysis\n  - Always plot the data first\n    - If there are clear sections in the data, it might be good to analyze each section separately\n\n## Best Linear Predictor\nLet $(X_t, t \\in \\Z)$ be a time series with $Var(X_t) < \\infty$ for $t \\in \\Z$ and\n$X^n := (X_{t_1},\\ldots, X_{t_n})$ be a collection of random variables of the time series at $n$ different times.\nThen the _best linear predictor of $X_t$ is given by\n$$\nb_t^l(X^n) = a_0 + a_1 X_{t_n} + \\cdots + a_n X_{t_1}\n$$\nwhere the coefficients are determined by the linear equations\n\n  1. $E(X_t - b_t^l(X^n)) = 0$\n  2. $E(X_{t_j}(X_t - b_t^l(X^n))) = 0$ for all $j = 1,\\ldots,n$.\n\nIf X is stationary, with mean $\\mu$ and autocovariance function $\\gamma$, the coefficients are determined by \n$$\na_0 = \\mu (1 - \\sum_{i = 1}^n a_i)\n$$\nand\n$$\n(\\gamma(t_{n + 1 - j} - t_{n + 1 - i}))_{i,j = 1}^n (a_1,\\ldots,a_n)^T = (\\gamma(t - t_n),\\ldots, \\gamma(t - t_1))^T\n$$\n\nThe mean square error is:\n\n$$\nMSE(b_t^l(X^n), X_t) = E[(b_t^l(X^n) - X_t)^2] = \\gamma(0) - (a_1, \\ldots, a_n)(\\gamma(t - t_n), \\ldots, \\gamma(t - t_1))^T\n$$\n\nNote: when $X^n := (X_1, \\ldots, X_n)$ then the coefficients $(a_0,\\ldots,a_n)$ for prediction of $X_{n + h}$\nand\n$$\n(\\gamma(i - j)_{i,j = 1}^n) (a_1,\\ldots, a_n)^T = (\\gamma(h), \\ldots, \\gamma(h + n - 1))^T\n$$\n\n### Example\nThe notation $t_1,\\ldots, t_n$ was confusing to me at first.\nA good example that shown how it works is if we have an $AR(1)$ process,\n$$\nX_t - \\phi_1 X_{t - 1} = Z_t\n$$\nAssume that we observe values at $X_1$ and $X_3$, but are missing a value for $X_2$.\nWe then have $t_1 = 1$, $t_2 = 3$, with $n = 2$.\nWe want to find:\n$$\nb_2^l(X^1,X^3) = a_0 + a_1 X_3 + a_2 X_1\n$$\nWe have that $a_0 = 0$, since the process has mean zero.\nIt then follows that,\n\n$$\n\\begin{aligned}\n  \\begin{pmatrix}\n    \\gamma(t_{3 + 1 - 1} - t_{3 + 1 - 1}) & \\gamma(t_{3 + 1 - 2} - t_{3 + 1 - 1})\\\\\n     \\gamma(t_{3 + 1 - 1} - t_{3 + 1 - 2}) &\\gamma(t_{3 + 1 - 1} - t_{3 + 1 - 1})\n  \\end{pmatrix} \n  \\begin{pmatrix}\n    a_1\\\\\n    a_2\n  \\end{pmatrix}\n  &=\n  \\begin{pmatrix}\n    \\gamma(2 - t_{2})\\\\\n    \\gamma(2 - t_{1})\n  \\end{pmatrix}\\\\\n  \\begin{pmatrix}\n    \\gamma(0) & \\gamma(3 - 1)\\\\\n     \\gamma(3 - 1) &\\gamma(0)\n  \\end{pmatrix} \n  \\begin{pmatrix}\n    a_1\\\\\n    a_2\n  \\end{pmatrix}\n  &=\n  \\begin{pmatrix}\n    \\gamma(2 - 3)\\\\\n    \\gamma(2 - 1)\n  \\end{pmatrix}\\\\\n  \\begin{pmatrix}\n    1 & \\phi_1^2\\\\\n     \\phi_1^2 & 1\n  \\end{pmatrix} \n  \\begin{pmatrix}\n    a_1\\\\\n    a_2\n  \\end{pmatrix}\n  &=\n  \\begin{pmatrix}\n    \\phi_1\\\\\n    \\phi_1\n  \\end{pmatrix}\n\\end{aligned}\n$$\n\nWhich leads to a solution\n$$\na_1 = a_2 = \\frac{\\phi_1}{1 + \\phi_1^2}\n$$\n\n## ARMA(p,q)\n$\\{X_t\\}$ is an ARMA(p,q) process if $\\{X_t\\}$ is _stationary_ and if for every $t$,\n$$\nX_t - \\sum_{i = 1}^p \\phi_i X_{t-i} = Z_t + \\sum_{j = 1}^q \\theta_j Z_{t - j}\n$$\nwhere $\\{Z_t\\} \\sim WN(0, \\sigma^2)$ and the polynomials $(1 - \\sum_{i = 1}^p \\phi_i z^i)$ and $(1 + \\sum_{j = 1}^q \\theta_j z^j)$ have no common factors.\n\n## Causality\nAn ARMA(p,q) process $\\{X_t\\}$ is _causal_, if there exists constants $\\{\\psi_t\\}$ such that\n$$\n\\sum_{j = 0}^\\infty | \\psi_{j} | < \\infty\n$$\nand\n$$\nX_t = \\sum_{j = 0}^\\infty \\psi_{j} Z_{t - j}\n$$\nfor all $t$. That is, if we can represent the ARMA(p,q) process $\\{X_t\\}$ as a $MA(\\infty)$ process.\n\nHow to actually check? Use the equivalent condition:\n$$\n\\phi(z) = 1 - \\sum_{i = 1}^p \\phi_i z^i \\not = 0 \\quad \\text{for all}~|z| \\leq 1\n$$\nThat is, that $\\phi(z)$ has no roots _inside_ (or that all root are outside the unit circle).\n\n### Finding Causal Representation\nTo represent our (causal) ARMA(p,q) process in the form:\n$$\n  X_t = \\sum_{j = 0}^\\infty \\psi_j Z_{t - j}\n$$\nThe sequence of $\\{\\psi_j\\}$ is determined by the relation $\\psi(z) = \\sum_{j = 0}^\\infty \\psi_j z^j = \\theta(z) / \\phi(z)$, or equivalently:\n$$\n\\psi_j - \\sum_{k = 1}^p \\phi_k \\psi_{j - k} = \\theta_j, ~j = 0,1,\\ldots\n$$\nwith $\\theta_0 := 1, \\theta_j := 0$ for j > q and $\\psi_j := 0$ for $j < 0$.\n\n### Finding invertible (AR($\\infty$)) representation\nTo represent our invertible ARMA(p,q) process in the form:\n$$\nZ_t = \\sum_{j = 0}^\\infty \\pi_j X_{t - j}\n$$\nwe find $\\{\\pi_j\\}$ by the equations\n$$\n\\pi_j + \\sum_{k = 1}^q \\theta_k \\pi_{j - k} = -\\phi_j, ~j = 0,1,\\ldots,\n$$\nwhere $\\phi_0 := -1,~ \\phi_j := 0$ for $j > p$, and $\\pi_j := 0$ for $j < 0$.\n\n## Model Building for ARMA processes\n  - Remove trend and seasonality until you believe the dta can be modeled as a stationary time series.\n  - Identify the order of the ARMA process for the time series\n    - Either look at ACF/PACF\n    - or by fitting (using maximum likelihood or Hannan-Rissanen estimation) sucessively higher order ARMA(p,q) to the data and choosing p, q to minimize either the AICC or BIC.\n  - Estimate the final model using maximum likelihood\n  - Compute the residuals $\\hat{R}_t$ and check that they are consistent with the specified distribution and temporal covariance structure for $Z_t$.\n    - If they are, then the model is considered adequate for the data.\n\n## Autoregressive Processes - AR(p)\n$$\nX_t - \\sum_{j = 1}^p \\phi_j X_{t - j} = Z_t\n$$\n\n  - AR(p) is not necessarily stationary!\n\n### AR(1) Example\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n### AR(2)\nCan simulate using the function `astsa::arima.sim` function\n$$\nX_t = Z_t + 0.7 \\cdot X_{t - 1} + 0.2 \\cdot X_{t - 2}\n$$\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n## Moving Average Processes - MA(q)\n$$\nX_t = Z_t + \\sum_{j = 1}^q \\theta_j Z_{t - j}\n$$\nwith $Z_t \\sim WN(0, \\sigma^2)$. At lag greater than or equal to q, the ACF should be zero.\n\n### MA(2) example\n$$\nX_t = Z_t + 0.8 \\cdot Z_{t - 1} + 0.2 \\cdot Z_{t - 2}\n$$\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThe autocorrelation function\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## ARMA(p,q)\n  - The partial autocorrelation function PACF of an ARMA(p,q) process X can be thought of as the correlation between $X_t$ and $X_{t + h}$ when adjusting for the intervening observations $X_{t + 1}, \\ldots, X_{t + h - 1}$.\n    - Can be used to detect seasonality: If you have monthly data and you see a big spike at $\\hat{\\alpha}(12)$, it is likely that you see a periodic effect corresponding to a calendar\nyear, so you should remove the seasonality.\n\n### ACF and PACF\n\n| Conditional Mean Model | ACF                   | PACF                  |\n|------------------------|-----------------------|-----------------------|\n| AR(p)                  | Tails off gradually   | Cuts off after p lags |\n| MA(q)                  | Cuts off after q lags | Tails off gradually   |\n| ARMA(p,q)              | Tails off gradually   | Tails off gradually   |\n\nSource: https://se.mathworks.com/help/econ/autocorrelation-and-partial-autocorrelation.html\n\n## Innovations Algorithm\nUsed to compute the best linear predictor, $b_{n + 1}^l(X^n)$ more computationally efficiently than solving a system of $n$ linear equations.\nCan be applied to all time series with finite second moments.\nAssume we have a time series $(X_t, t \\in \\mathbb Z)$ with zero mean, and finite second moment $E[X_t^2] < + \\infty$ for all $t \\in \\mathbb Z$ and covariance\n$$\nCov(X_i, X_j) = \\kappa(i,j)\n$$\nWe denote the best linear one-step predictors as \n$$\n\\hat{X}_n := \\begin{cases}\n  0 & \\text{for n = 1}\\\\\n  b_{n}^l(X^{n - 1}) & \\text{for n > 1}\n\\end{cases}\n$$\nand the mean squared errors as\n$$\nv_n := MSE(\\hat{X}_{n+1}, X_{n + 1}) = E[(\\hat{X}_{n + 1} - X_{n + 1})^2]\n$$\n\nThere exists coefficients $(\\theta_{ij}, 1 \\leq j \\leq i \\leq n)$ such that the best linear predictors satisfy\n$$\n\\hat{X}_{n + 1} = \\begin{cases}\n  0 & \\text{for } n = 0\\\\\n  \\sum_{j = 1}^n \\theta_{nj}(X_{n + 1 - j} - \\hat{X}_{n+1-j}) & \\text{for } n \\geq 1\n\\end{cases}\n$$\nWe compute the coefficients $\\theta_{n1},\\ldots, \\theta_{nn}$ recursively from the equations\n$$\nv_0 := \\kappa(1,1)\n$$\nand\n$$\n\\theta_{n (n - k)} := v_k^{-1} \\left( \n  \\kappa(n + 1, k + 1) - \\sum_{j = 0}^{k - 1} \\theta_{k (k - j)} \\theta_{n (n - j)} v_j\n\\right)\n$$\n\n\n## GARCH/ARCH\n\n### Conditional Maximum Likelihood\n\nThe MLEs $(\\hat{\\alpha}_0, \\ldots, \\hat{\\alpha}_p, \\hat{\\beta}_1, \\ldots, \\hat{\\alpha}_q, \\hat{\\theta}_Z)$ are obtained by maximizing the _conditional likelihood function_\n$$\nL(\\alpha_0, \\ldots, \\alpha_p, \\beta_1, \\ldots, \\alpha_q, \\theta_Z) = \\prod_{t = p + 1} \\frac{1}{\\sigma_t} f_Z \\left( \\frac{x_t}{\\sigma_t}\\right)\n$$\nwhere $f_Z$ is the density of the white noise Z and $\\theta_Z$ is any other parameter Z depends on (such as degrees of freedom if Z is t-distributed).\n\nIt $Z \\sim IIDN(0,1)$ then,\n$$\n\\begin{aligned}\nf_Z \\left( \\frac{x_t}{\\sigma_t}\\right) &= \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( - \\frac{X_t^2}{2 \\sigma_t^2}\\right)\\\\\nL(\\alpha_0, \\ldots, \\alpha_p, \\beta_1, \\ldots, \\alpha_q, \\theta_Z) &= \\prod_{t = p + 1}^n \\frac{1}{\\sigma_t} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( - \\frac{X_t^2}{2 \\sigma_t^2}\\right)\\\\\n- \\ln L(\\alpha_0, \\ldots, \\alpha_p, \\beta_1, \\ldots, \\alpha_q, \\theta_Z) &= \\sum_{t = p + 1}^n \\ln{\\sigma_t} + \\frac{1}{2} \\ln(2\\pi)as + \\frac{1}{2} \\frac{X_t^2}{\\sigma_t^2}\\\\\n&= \\frac{1}{2} \\sum_{t = p + 1}^n 2 \\ln{\\sigma_t} + \\ln(2\\pi) + \\frac{X_t^2}{\\sigma_t^2}\\\\\n&= \\frac{1}{2} \\sum_{t = p + 1}^n \\ln{\\sigma_t^2} + \\ln(2\\pi) + \\frac{X_t^2}{\\sigma_t^2}\n\\end{aligned}\n$$\n\n### Acknowledgements\n\n\nThis blog post was made possible thanks to:\n\n* <a id='cite-Xie_2017'></a>(<a href='https://bookdown.org/yihui/blogdown/'>Xie, Hill, and Thomas, 2017</a>)\n* <a id='cite-Boettiger_2021'></a>(<a href='https://CRAN.R-project.org/package=knitcitations'>Boettiger, 2021</a>)\n* <a id='cite-Wickham_2021'></a>(<a href='https://CRAN.R-project.org/package=sessioninfo'>Wickham, Chang, Flight, Müller et al., 2021</a>)\n\n### References\n\n\n<p><a id='bib-Boettiger_2021'></a><a href=\"#cite-Boettiger_2021\">[1]</a><cite>\nC. Boettiger.\n<em>knitcitations: Citations for 'Knitr' Markdown Files</em>.\nR package version 1.0.12.\n2021.\nURL: <a href=\"https://CRAN.R-project.org/package=knitcitations\">https://CRAN.R-project.org/package=knitcitations</a>.</cite></p>\n\n<p><a id='bib-Wickham_2021'></a><a href=\"#cite-Wickham_2021\">[2]</a><cite>\nH. Wickham, W. Chang, R. Flight, K. Müller, et al.\n<em>sessioninfo: R Session Information</em>.\nR package version 1.2.2.\n2021.\nURL: <a href=\"https://CRAN.R-project.org/package=sessioninfo\">https://CRAN.R-project.org/package=sessioninfo</a>.</cite></p>\n\n<p><a id='bib-Xie_2017'></a><a href=\"#cite-Xie_2017\">[3]</a><cite>\nY. Xie, A. P. Hill, and A. Thomas.\n<em>blogdown: Creating Websites with R Markdown</em>.\nISBN 978-0815363729.\nBoca Raton, Florida: Chapman and Hall/CRC, 2017.\nURL: <a href=\"https://bookdown.org/yihui/blogdown/\">https://bookdown.org/yihui/blogdown/</a>.</cite></p>\n\n\n### Reproducibility\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Catalina 10.15.7\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-11\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n ! package       * version date (UTC) lib source\n P assertthat      0.2.1   2019-03-21 [?] CRAN (R 4.2.0)\n P backports       1.4.1   2021-12-13 [?] CRAN (R 4.2.0)\n P bibtex          0.5.0   2022-09-25 [?] CRAN (R 4.2.0)\n P cli             3.4.1   2022-09-23 [?] CRAN (R 4.2.0)\n P colorspace      2.0-3   2022-02-21 [?] CRAN (R 4.2.0)\n P DBI             1.1.3   2022-06-18 [?] CRAN (R 4.2.0)\n P digest          0.6.31  2022-12-11 [?] CRAN (R 4.2.1)\n P dplyr           1.0.10  2022-09-01 [?] CRAN (R 4.2.0)\n P evaluate        0.18    2022-11-07 [?] CRAN (R 4.2.0)\n P fansi           1.0.3   2022-03-24 [?] CRAN (R 4.2.0)\n P fastmap         1.1.0   2021-01-25 [?] CRAN (R 4.2.0)\n P generics        0.1.3   2022-07-05 [?] CRAN (R 4.2.0)\n P ggplot2       * 3.4.0   2022-11-04 [?] CRAN (R 4.2.0)\n P glue            1.6.2   2022-02-24 [?] CRAN (R 4.2.0)\n P gtable          0.3.1   2022-09-01 [?] CRAN (R 4.2.0)\n P htmltools       0.5.4   2022-12-07 [?] CRAN (R 4.2.0)\n P htmlwidgets     1.5.4   2021-09-08 [?] CRAN (R 4.2.0)\n P httr            1.4.4   2022-08-17 [?] CRAN (R 4.2.1)\n P jsonlite        1.8.4   2022-12-06 [?] CRAN (R 4.2.1)\n P knitcitations * 1.0.12  2021-01-10 [?] CRAN (R 4.2.0)\n P knitr           1.41    2022-11-18 [?] CRAN (R 4.2.1)\n P lifecycle       1.0.3   2022-10-07 [?] CRAN (R 4.2.0)\n P lubridate       1.9.0   2022-11-06 [?] CRAN (R 4.2.0)\n P magrittr        2.0.3   2022-03-30 [?] CRAN (R 4.2.0)\n P munsell         0.5.0   2018-06-12 [?] CRAN (R 4.2.0)\n P pillar          1.8.1   2022-08-19 [?] CRAN (R 4.2.0)\n P pkgconfig       2.0.3   2019-09-22 [?] CRAN (R 4.2.0)\n P plyr            1.8.8   2022-11-11 [?] CRAN (R 4.2.0)\n P R6              2.5.1   2021-08-19 [?] CRAN (R 4.2.0)\n P Rcpp            1.0.9   2022-07-08 [?] CRAN (R 4.2.0)\n P RefManageR      1.4.0   2022-09-30 [?] CRAN (R 4.2.0)\n   renv            0.16.0  2022-09-29 [1] CRAN (R 4.2.0)\n P rlang           1.0.6   2022-09-24 [?] CRAN (R 4.2.0)\n P rmarkdown       2.18    2022-11-09 [?] CRAN (R 4.2.0)\n P rstudioapi      0.14    2022-08-22 [?] CRAN (R 4.2.0)\n P scales          1.2.1   2022-08-20 [?] CRAN (R 4.2.0)\n P sessioninfo   * 1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n P stringi         1.7.8   2022-07-11 [?] CRAN (R 4.2.0)\n P stringr         1.5.0   2022-12-02 [?] CRAN (R 4.2.0)\n P tibble          3.1.8   2022-07-22 [?] CRAN (R 4.2.0)\n P tidyselect      1.2.0   2022-10-10 [?] CRAN (R 4.2.0)\n P timechange      0.1.1   2022-11-04 [?] CRAN (R 4.2.0)\n P utf8            1.2.2   2021-07-24 [?] CRAN (R 4.2.0)\n P vctrs           0.5.1   2022-11-16 [?] CRAN (R 4.2.0)\n P withr           2.5.0   2022-03-03 [?] CRAN (R 4.2.0)\n P xfun            0.35    2022-11-16 [?] CRAN (R 4.2.0)\n P xml2            1.3.3   2021-11-30 [?] CRAN (R 4.2.0)\n P yaml            2.3.6   2022-10-18 [?] CRAN (R 4.2.0)\n\n [1] /Users/stefaneng/personal_devel/stefanengineering.comV3/renv/library/R-4.2/x86_64-apple-darwin17.0\n [2] /Users/stefaneng/personal_devel/stefanengineering.comV3/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/84ba8b13\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}