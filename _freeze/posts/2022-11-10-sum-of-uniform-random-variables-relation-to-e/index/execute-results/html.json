{
  "hash": "16cc9f99d34435b715c03c5e4789690f",
  "result": {
    "markdown": "---\ntitle: Sum of uniform random variables until sum is greater than one\nauthor: R package build\ndate: '2022-11-10'\nslug: sum-of-uniform-random-variables-relation-to-e\ncategories:\n  - math\ntags:\n  - probability\noutput:\n  blogdown::html_page:\n    toc: no\n    fig_width: 5\n    fig_height: 5\nlink-citations: yes\ncsl: ../../static/bibtex/acm-sig-proceedings.csl\nbibliography: ../../static/bibtex/probability.bib  \n---\n\n\n## Introduction\n\nI saw this problem on [r/probabilitytheory](https://www.reddit.com/r/probabilitytheory/comments/rii5n6/simulation_of_eulers_number_oc/)\n\n> If you pick a uniformly random real number on [0,1] and repeat this until the sum of numbers picked is greater than 1, you'll on average pick $e \\approx 2.718$ numbers\n\nPosed in a way that we can actually begin to solve this.\n\n> Sample independent uniform random variables $U_1, U_2, \\ldots$ and let $S_n = \\sum_{i = 1}^n U_i$. Let $N$ be the first integer $n$ such that $S_n > 1$. Find $E[N]$\n\nBonus question: What is the $E[S_n]$? Can we find its distribution?\n\nOf course, the first step is to replicate the simple simulation.\n\n## Simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample from independent uniform U(0,1) distributions and stop when the sum\n# is greater than 1. Let N be that first sum. Then E[N] = e\n\nsim_sum <- function(t = 1) {\n  s_n <- 0\n  n <- 0\n  while(s_n < 1) {\n    s_n <- s_n + runif(1)\n    n <- n + 1\n  }\n  c(n = n, s_n = s_n)\n}\n\n\nreps <- 1e4\nN_sim <- data.frame(t(replicate(reps, sim_sum())))\nN_sim_table <- table(N_sim$n)\nN_sim_prob <- N_sim_table / reps\n\nK <- as.numeric(names(N_sim_table))\n\nmean_N <- mean(N_sim$n)\nplot(K, N_sim_prob, type = 'b', ylim = c(0, 1), ylab = 'P(N = n)', xlab = 'N')\nabline(v = mean_N, lty = 2)\ntext(x = mean_N + 1, y = 0.75, sprintf('Mean(n) = %.03f', mean_N))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Proof\n\nThe idea of the proof is to directly solve:\n\n$$\nE[n] = \\sum_{n = 1}^\\infty n \\cdot P(N = n)\n$$\n\nSo we need to calculate, $P(N = n)$.\nThis is the same as, $P(S_{n - 1} \\leq 1 \\text{ and } S_n > 1)$.\nIf we calculate $P(S_n \\leq x) = F_{S_n}(x)$ we can complete the proof.\n\n### $P(S_n \\leq x)$\n\nUsing the proof from [this answer on math.stackexchange](https://math.stackexchange.com/a/1683574/76510),\n\nwhen $x \\in [0,1]$, claim is that $P(S_n \\leq t) = \\frac{x^n}{n!}$. When $n = 1$, then $P(S_1 \\leq t) = P(U_1 \\leq t) = t$. Assume true for $n$. Then,\n\n$$\n\\begin{aligned}\nP(S_{n + 1} \\leq x) &= P(S_n + U_{n + 1} \\leq t)\\\\\n&= \\int_0^1 P(S_n + u \\leq t) \\underbrace{f(u)}_{1} ~du && S_n \\text{ and } U_{n + 1} \\text{ independent}\\\\\n&=  \\int_0^1 P(S_n \\leq t - u) ~du\\\\\n&=  \\int_0^t \\underbrace{P(S_n \\leq t - u)}_{\\text{Induction Hypothesis}} ~du && \\text{Since } P(S_n \\leq t - u) = 0 \\text{ when } u \\in [t, 1]\\\\\n&= \\int_0^t \\frac{(t - u)^n}{n!} ~du \\\\\n&= \\frac{1}{n!} \\left( \\frac{-1}{n + 1} (t - u)^{n + 1}\\Big|^{u = t}_{u = 0} \\right)\\\\\n&= \\frac{t^{n + 1}}{(n + 1)!}\n\\end{aligned}\n$$\n\n### PMF of $S_n$\nSince $F_{S_n}(x) = \\frac{x^n}{n!}$ we have\n$$\n\\begin{aligned}\nf_{S_n}(x) &= \\frac{dF_{S_n}}{dx}\\\\\n&= n \\frac{x^{n - 1}}{n!}\n\\end{aligned}\n$$\n\n### $P(N = n)$\n$$\n\\begin{aligned}\nP(N = n) &= P(S_{n - 1} \\leq 1 \\text{ and } S_n > 1)\\\\\n&= P(S_n > 1 | S_{n - 1} \\leq 1) P(S_{n - 1} \\leq 1)\\\\\n&= \\int_0^1 P(U_n + x > 1 | S_{n - 1} = x \\leq 1) \\underbrace{P(s \\leq 1 | S_{n - 1} = s)}_{1} f_{S_{n - 1}}(x)~dx\\\\\n&= \\int_0^1 P(U_n + x > 1)~f_{S_{n - 1}}(x)~dx && U_n \\text{ and } S_{n - 1} \\text{ independent}\\\\\n&= \\int_0^1 (1 - F_n(1 - x))~f_{S_{n - 1}}(x)~dx\\\\\n&= \\int_0^1 x (n - 1)\\frac{x^{n - 2}}{(n - 1)!}~dx\\\\\n&= \\frac{n - 1}{(n - 1)!} \\int_0^1 x^{n - 1}~dx\\\\\n&= \\frac{n - 1}{n (n - 1)!} = \\frac{n - 1}{n!}\n\\end{aligned}\n$$\n\nTo double check the answer we can simulate\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is formula we computed analytically\n# (K - 1) / (factorial(K))\nK <- as.numeric(names(N_sim_table))\nexpected_probs <- (K - 1) / (factorial(K))\n\nplot(K, N_sim_prob, type = 'b', xlab = 'n', ylab = 'Prob(N = n)', ylim = c(0, 1), yaxp = c(0, 1, 4))\nlines(K, expected_probs, type = 'b', col = 'red')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### E[N] = e\n\n$$\n\\begin{aligned}\nE[N] &= \\sum_{n = 2}^\\infty n \\cdot P(N = n)\\\\\n&=  \\sum_{n = 2}^\\infty \\frac{n (n - 1)}{n!}\\\\\n&= \\sum_{n = 2}^\\infty \\frac{1}{(n - 2)!}\\\\\n&=  \\sum_{n = 0}^\\infty \\frac{1}{n!} && \\text{since } \\sum_{n = 0}^\\infty \\frac{x^n}{n!} = e^x\\\\\n&= e\n\\end{aligned}\n$$\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}