---
title: Linear Algebra in R
author: Stefan Eng
date: '2022-06-24'
slug: linear-algebra-R
categories:
  - R
  - math
tags:
  - R
draft: yes
output:
  html: default
  blogdown::html_page:
    toc: no
    fig_width: 5
    fig_height: 5
link-citations: yes
csl: ../../static/bibtex/acm-sig-proceedings.csl
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
## Load frequently used packages for blog posts
library(sessioninfo) # for session_info()

## For R images to display well in the RSS feed (disable for local preview)
# knitr::opts_knit$set(base.url = 'stefanengineering.com/post/')

# Don't show code by default
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, comment = NA, message = FALSE)
knitr::opts_knit$set(global.par = TRUE)
```

## Setup
```{r}
library(tidyverse)
library(here)

# CB Palette like ESL
cbPalette <- c(
  "#999999", "#E69F00", "#56B4E9", "#009E73",
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# Set the theme
theme_set(
  theme_minimal(base_size = 15, base_family = "Arial") %+replace%
    theme(plot.caption = element_text(size = 9, color = "gray50", hjust=1))
)
```

## Introduction
Most of this content was taken from [@wood_gam_book]

## QR Decomposition
Any real-valued matrix $X$ ($n \times p$) can be decomposed as
$$
X = Q_f R = Q\begin{bmatrix}R\\0\end{bmatrix}
$$
where $Q$ is an $n \times n$ orthogonal matrix. In the alternate formulation, $Q_f$ is the first $p$ columns of $Q$, so $Q_f$ is $n \times p$ with orthogonal columns. $R$ is a $p \times p$ upper triangular matrix such that $R_{i,j} = 0$ if $i > j$.
Some of the nice properties about these matrices are that 

$$
\begin{aligned}
Q^T &= Q^{-1}\\
Q^T Q &= Q Q^T = I_{n}\\
Q_f^T Q_f &= I_{p}\\
Q u \cdot Q v &= u \cdot v && \text{for } u,v \in R^{n}\\
\| Q u \| &= \| u \| && \text{for all } u \in R^{n}
\end{aligned}
$$

## Length is preserved
Assume $Q$ is a $n \times n$ orthogonal matrix and $v$ is a $n \times 1$ vector. Then,

$$
\begin{aligned}
\|Q v \| &= Qv \cdot Qv\\
&= (Qv)^T Qv\\
&= v Q^T Q v\\
&= v \cdot v\\
&= \|v \|
\end{aligned}
$$

### Determinant of Q matrix
[Source](https://sites.math.rutgers.edu/~cherlin/Courses/250/Lectures/250L26.html)

Since $1/\det(Q) = \det(Q^{-1}) = \det(Q^T) = det(Q)$,
then $\det(Q)^2 = 1$ so $\det(Q) = \pm 1$

### When to use QR decomposition?

## Cholesky Decomposition


## Assorted Functions

  - Use `crossprod(X)` instead of `t(X) %*% X` to compute $X^T X$
    - `crossprod(X,Y)` computes $X^T Y$
  - Use `tcrossprod(Y)` instead of `Y %*% t(Y)` to compute $Y Y^T$
    - `tcrossprod(X,Y)` computes $X Y^T$

## References

## Reproducibility

```{r reproducibility, echo = FALSE}
## Reproducibility info
options(width = 120)
session_info()
```
