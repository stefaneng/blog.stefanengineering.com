[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "stefanengineering.com",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum of uniform random variables until sum is greater than one\n\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\nR package build\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint distribution of sums of exponential random variables\n\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nMay 17, 2020\n\n\nStefan Eng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability of even/odd using probability generating functions\n\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2020\n\n\nStefan Eng\n\n\n\n\n\n\n  \n\n\n\n\nInside a Basel Novartis Internship\n\n\n\n\n\n\n\njob\n\n\npersonal\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2019\n\n\nStefan Eng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic R Markdown Reports with Shiny\n\n\n\n\n\n\n\nR\n\n\ndevelopment\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2019\n\n\nStefan Eng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Time Series\n\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2019\n\n\nStefan Eng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1990 to 1992 Census Crime Rate Prediction.\n\n\n\n\n\n\n\nR\n\n\nschool\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2019\n\n\nStefan Eng\n\n\n\n\n\n\n  \n\n\n\n\nCloze Deletion Prediction with LSTM Neural Networks\n\n\n\n\n\n\n\nmachine-learning\n\n\nproject\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2018\n\n\nStefan Eng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html",
    "href": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html",
    "title": "Sum of uniform random variables until sum is greater than one",
    "section": "",
    "text": "I saw this problem on r/probabilitytheory\n\nIf you pick a uniformly random real number on [0,1] and repeat this until the sum of numbers picked is greater than 1, you’ll on average pick \\(e \\approx 2.718\\) numbers\n\nPosed in a way that we can actually begin to solve this.\n\nSample independent uniform random variables \\(U_1, U_2, \\ldots\\) and let \\(S_n = \\sum_{i = 1}^n U_i\\). Let \\(N\\) be the first integer \\(n\\) such that \\(S_n > 1\\). Find \\(E[N]\\)\n\nBonus question: What is the \\(E[S_n]\\)? Can we find its distribution?\nOf course, the first step is to replicate the simple simulation."
  },
  {
    "objectID": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html#simulation",
    "href": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html#simulation",
    "title": "Sum of uniform random variables until sum is greater than one",
    "section": "Simulation",
    "text": "Simulation\n\n# Sample from independent uniform U(0,1) distributions and stop when the sum\n# is greater than 1. Let N be that first sum. Then E[N] = e\n\nsim_sum <- function(t = 1) {\n  s_n <- 0\n  n <- 0\n  while(s_n < 1) {\n    s_n <- s_n + runif(1)\n    n <- n + 1\n  }\n  c(n = n, s_n = s_n)\n}\n\n\nreps <- 1e4\nN_sim <- data.frame(t(replicate(reps, sim_sum())))\nN_sim_table <- table(N_sim$n)\nN_sim_prob <- N_sim_table / reps\n\nK <- as.numeric(names(N_sim_table))\n\nmean_N <- mean(N_sim$n)\nplot(K, N_sim_prob, type = 'b', ylim = c(0, 1), ylab = 'P(N = n)', xlab = 'N')\nabline(v = mean_N, lty = 2)\ntext(x = mean_N + 1, y = 0.75, sprintf('Mean(n) = %.03f', mean_N))"
  },
  {
    "objectID": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html#proof",
    "href": "posts/2022-11-10-sum-of-uniform-random-variables-relation-to-e/index.html#proof",
    "title": "Sum of uniform random variables until sum is greater than one",
    "section": "Proof",
    "text": "Proof\nThe idea of the proof is to directly solve:\n\\[\nE[n] = \\sum_{n = 1}^\\infty n \\cdot P(N = n)\n\\]\nSo we need to calculate, \\(P(N = n)\\). This is the same as, \\(P(S_{n - 1} \\leq 1 \\text{ and } S_n > 1)\\). If we calculate \\(P(S_n \\leq x) = F_{S_n}(x)\\) we can complete the proof.\n\n\\(P(S_n \\leq x)\\)\nUsing the proof from this answer on math.stackexchange,\nwhen \\(x \\in [0,1]\\), claim is that \\(P(S_n \\leq t) = \\frac{x^n}{n!}\\). When \\(n = 1\\), then \\(P(S_1 \\leq t) = P(U_1 \\leq t) = t\\). Assume true for \\(n\\). Then,\n\\[\n\\begin{aligned}\nP(S_{n + 1} \\leq x) &= P(S_n + U_{n + 1} \\leq t)\\\\\n&= \\int_0^1 P(S_n + u \\leq t) \\underbrace{f(u)}_{1} ~du && S_n \\text{ and } U_{n + 1} \\text{ independent}\\\\\n&=  \\int_0^1 P(S_n \\leq t - u) ~du\\\\\n&=  \\int_0^t \\underbrace{P(S_n \\leq t - u)}_{\\text{Induction Hypothesis}} ~du && \\text{Since } P(S_n \\leq t - u) = 0 \\text{ when } u \\in [t, 1]\\\\\n&= \\int_0^t \\frac{(t - u)^n}{n!} ~du \\\\\n&= \\frac{1}{n!} \\left( \\frac{-1}{n + 1} (t - u)^{n + 1}\\Big|^{u = t}_{u = 0} \\right)\\\\\n&= \\frac{t^{n + 1}}{(n + 1)!}\n\\end{aligned}\n\\]\n\n\nPMF of \\(S_n\\)\nSince \\(F_{S_n}(x) = \\frac{x^n}{n!}\\) we have \\[\n\\begin{aligned}\nf_{S_n}(x) &= \\frac{dF_{S_n}}{dx}\\\\\n&= n \\frac{x^{n - 1}}{n!}\n\\end{aligned}\n\\]\n\n\n\\(P(N = n)\\)\n\\[\n\\begin{aligned}\nP(N = n) &= P(S_{n - 1} \\leq 1 \\text{ and } S_n > 1)\\\\\n&= P(S_n > 1 | S_{n - 1} \\leq 1) P(S_{n - 1} \\leq 1)\\\\\n&= \\int_0^1 P(U_n + x > 1 | S_{n - 1} = x \\leq 1) \\underbrace{P(s \\leq 1 | S_{n - 1} = s)}_{1} f_{S_{n - 1}}(x)~dx\\\\\n&= \\int_0^1 P(U_n + x > 1)~f_{S_{n - 1}}(x)~dx && U_n \\text{ and } S_{n - 1} \\text{ independent}\\\\\n&= \\int_0^1 (1 - F_n(1 - x))~f_{S_{n - 1}}(x)~dx\\\\\n&= \\int_0^1 x (n - 1)\\frac{x^{n - 2}}{(n - 1)!}~dx\\\\\n&= \\frac{n - 1}{(n - 1)!} \\int_0^1 x^{n - 1}~dx\\\\\n&= \\frac{n - 1}{n (n - 1)!} = \\frac{n - 1}{n!}\n\\end{aligned}\n\\]\nTo double check the answer we can simulate\n\n# This is formula we computed analytically\n# (K - 1) / (factorial(K))\nK <- as.numeric(names(N_sim_table))\nexpected_probs <- (K - 1) / (factorial(K))\n\nplot(K, N_sim_prob, type = 'b', xlab = 'n', ylab = 'Prob(N = n)', ylim = c(0, 1), yaxp = c(0, 1, 4))\nlines(K, expected_probs, type = 'b', col = 'red')\n\n\n\n\n\n\nE[N] = e\n\\[\n\\begin{aligned}\nE[N] &= \\sum_{n = 2}^\\infty n \\cdot P(N = n)\\\\\n&=  \\sum_{n = 2}^\\infty \\frac{n (n - 1)}{n!}\\\\\n&= \\sum_{n = 2}^\\infty \\frac{1}{(n - 2)!}\\\\\n&=  \\sum_{n = 0}^\\infty \\frac{1}{n!} && \\text{since } \\sum_{n = 0}^\\infty \\frac{x^n}{n!} = e^x\\\\\n&= e\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/2020-05-17-joint-distribution-of-sums-of-exponential-random-variables/index.html",
    "href": "posts/2020-05-17-joint-distribution-of-sums-of-exponential-random-variables/index.html",
    "title": "Joint distribution of sums of exponential random variables",
    "section": "",
    "text": "This is a problem from Ross’s Stochastic Processes [1]. Let \\[\n\\begin{aligned}\nS_1 &= X_1\\\\\nS_2 &= X_1 + X_2\\\\\nS_3 &= X_1 + X_2 + X_3\n\\end{aligned}\n\\] where \\(X_1, X_2, X_3\\) are i.i.d exponential random variables with rate \\(\\lambda\\). Find the joint distribution of \\(S_1, S_2, S_3\\).\nLet \\(f\\) be the PDF of each \\(X_1, X_2, X_3\\) (since identically distributed). Since \\(X_1, X_2, X_3\\) are independent the joint PDF is \\[\nf(x,y,z) = f(x) f(y) f(z) = \\lambda^3 e^{-\\lambda x} e^{-\\lambda y} e^{-\\lambda z}\n\\] Then we can find the joint CDF of \\(S_1, S_2, S_3\\) \\[\n\\begin{aligned}\nP(S_1 \\leq t_1, S_2 \\leq t_2, S_3 \\leq t_3) &= \\int_{0}^{t_1} \\int_{0}^{t_2 - x} \\int_{0}^{t_3 - x - y} f(x,y,z) ~dz~dy~dx\\\\\n&= \\int_{0}^{t_1} \\int_{0}^{t_2 - x} \\int_{0}^{t_3 - x - y} \\lambda e^{-\\lambda z} \\lambda e^{-\\lambda y} \\lambda e^{-\\lambda x}~dz~dy~dx\\\\\n&= \\int_{0}^{t_1} \\lambda e^{-\\lambda x} \\int_{0}^{t_2 - x} (1 - e^{-\\lambda (t_3 - x - y)}) \\lambda e^{-\\lambda y}~dy~dx\\\\\n&= \\int_{0}^{t_1} \\lambda e^{-\\lambda x} \\left[\\int_{0}^{t_2 - x} \\lambda e^{-\\lambda y}~dy -  \\int_{0}^{t_2 - x} e^{-\\lambda (t_3 - x)}~dy\\right]~dx\\\\\n&= \\int_{0}^{t_1} \\lambda e^{-\\lambda x} \\left[(1 - e^{-\\lambda (t_2 - x)}) - (t_2 - x) e^{-\\lambda (t_3 - x)}\\right]~dx\\\\\n&= \\int_{0}^{t_1} \\lambda e^{-\\lambda x} ~dx - \\int_{0}^{t_1} \\lambda e^{-\\lambda t_2} ~dx - \\int_{0}^{t_1} (t_2 - x) e^{-\\lambda t_3}~dx\\\\\n&= 1 - e^{-\\lambda t_1} - \\lambda t_1 e^{-\\lambda t_2} - t_1 t_2 e^{-\\lambda t_3} + \\frac{1}{2} t_1^2 e^{-\\lambda t_3}\n\\end{aligned}\n\\]\n\nSimulation\nWe can confirm these results with a simple simulation in R.\n\n# Computed joint CDF\nexpect_joint <- function(t1, t2, t3, lambda = 1) {\n  1 - exp(- lambda * t1) - lambda * t1 * exp(-lambda * t2) - \n    t1 * t2 * exp(-lambda * t3) + 1/2 * t1^2 *exp(- lambda * t3)\n}\n\n# Simulate 1000 realizations of S1, S2, S3\nsim <- function(t1, t2, t3, rate = 1, n = 1000) {\n  s1 <- rexp(n, rate)\n  s2 <- s1 + rexp(n, rate)\n  s3 <- s2 + rexp(n, rate)\n  \n  mean(s1 <= t1 & s2 <= t2 & s3 <= t3)\n}\n\n# P(S1 <= 1, S2 <= 2, S3 <= 3) with lambda = 1\nt1 <- 1\nt2 <- 2\nt3 <- 3\nrate <- 1\n# Replicate the simulation 1000 times\nsim_res <- replicate(1000, sim(t1, t2, t3, rate))\n\ncat(\"Simulated mean:\", round(mean(sim_res), 3))\n\nSimulated mean: 0.422\n\ncat(\"Expected joint distribution:\", round(expect_joint(t1, t2, t3, rate), 3))\n\nExpected joint distribution: 0.422\n\n\n```\n\n\n\n\n\n\n\n\nReferences\n\n[1] Ross, S.M. et al. 1996. Stochastic processes. Wiley New York."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html",
    "title": "Inside a Basel Novartis Internship",
    "section": "",
    "text": "This summer I had the privilege of doing a 3 month summer (2019) internship at Novartis’ head office in Basel, Switzerland. I worked in the Scientific Computing and Consulting team within Biostatistics. This post is about the non-technical aspect about the internship at Novartis, particularly focused on Basel. Most of the general information applies to other sites such as Cambridge (USA), East Hanover, or other locations. This post goes into details on\n\nApplication process\nWork visa\nInternship requirements\nCampus life\nPay and benefits\nNovartis provided housing (Some warning about it as well)\n\n\n\n\nAveraged about 46 hour weeks with the max being a 57 hour week\nMonthly salary of 2500 francs plus 600 for accommodation (pre-tax)\n5 weeks vacation prorated for the length of your internship (5.5 days of vacation for my 3 months)\nFlexible working hours and potential to work from home one day a week\n\n\n\n\nBuilding designed by Frank Gehry with restaurants and a large auditorium."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#application-process",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#application-process",
    "title": "Inside a Basel Novartis Internship",
    "section": "Application Process",
    "text": "Application Process\nI found the job on LinkedIn with the title “Intern - Biostatistics”. The job description must be identical for all jobs in the biostatistics department since my work was nothing like it was described in the posting. I applied through a fairly standard BrassRing website in February and a few days later received an email to set up and interview. The interview was done over Skype. It was a non-technical interview where we went over my job experience. Some of the other questions were standard such as “give me an example of when you dealt with a difficult person at work”. I was interviewed by my future team, two from Cambridge and one from Basel. The job described was completely different than the job posting but I ended up accepting anyway. The whole process from application to offer was fast and professional.\nI would say that if you are interested in Pharma and are cold-applying via the website then apply to all positions that are even remotely related to what you are interested in. Even better would be to find contacts within Novartis and find a job directly. Don’t be afraid to apply without pharma experience. I only met one other intern that had worked in pharma before their internship."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#work-visa",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#work-visa",
    "title": "Inside a Basel Novartis Internship",
    "section": "Work Visa",
    "text": "Work Visa\nMy contract with Novartis was just under 90 days which meant that I did not need an official work permit. Make sure to apply early if you plan to work for over 90 days. EU citizens (particularly western-EU) have a much easier time getting a permit than non-EU countries. One benefit of staying for longer than 90 days is that you are required to register with the Basel Kanton. You then can get apply for a half-price transportation card which makes traveling a bit cheaper."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#a-global-company",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#a-global-company",
    "title": "Inside a Basel Novartis Internship",
    "section": "A Global Company",
    "text": "A Global Company\nNovartis truly feels like a global company as many teams are split across the world. Often meeting are done over Skype or similar internal tool for video conferencing. My team in particular had 3 people in Basel and 4 in Cambridge (USA). I also worked with clients in East Hanover (New Jersey). This was both a up and downside for me because it means less face-to-face interaction. I am fairly introverted and wanted to work on my interpersonal skills as much as possible. Even large meetings with 80+ people might only have 8 people in a room on-site. Many people participate in the meetings from their office. I would have liked the presentations that I gave to have had a larger in-person audience. It doesn’t feel like my public speaking skills improved that much from giving presentations over Skype. If you are uncomfortable with public speaking this is probably a plus for you!\nAn interesting feature of Basel was the language. Since it is so close to both France and Germany there are quite a few people commuting across the border. Meetings here would often start with asking which language to use. The company language was english but there was always accompanying german. My teammate are french and often would have meetings in french. Depends on your team which language you work in."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#internship-requirements",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#internship-requirements",
    "title": "Inside a Basel Novartis Internship",
    "section": "Internship Requirements",
    "text": "Internship Requirements\nThere are not a lot of requirements for the Basel Novartis internship. Many interns have to give a end of internship presentation. I believe this was set up automatically in Cambridge and is a requirement. In Basel it seems that your supervisor has to set things up themselves. I ended up giving one bigger presentation and many to clients of my projects. It depends a lot on the field you are in as well.\nThere is also a two day welcome-day for all new employees which you should make sure to ask your supervisor about. I was unaware of it and was not registered for it. It seemed like a good way for new employees to meet each other and explore the opportunities around campus.\nYou will have to do some virtual training via the up4Growth internal platform. I had to do general safety training and well as ethics, and proper reporting of data. There are additional in-person trainings you will need to complete if you are working in a lab."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#hiring-interns",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#hiring-interns",
    "title": "Inside a Basel Novartis Internship",
    "section": "Hiring Interns",
    "text": "Hiring Interns\nNovartis has a large number of interns and post-docs. There were many Master’s students I met doing their thesis work at Novartis. The biostatistics department had many PhD students as well. Other interns were post-graduate and had already completed their degree. I did not meet anyone that was doing their Bachelors degree. At least at Basel, the hiring rate for interns seemed pretty low. This is just compared with my experience in the US. Many of the new hires in my department were senior level employees.\nMost of the interns at Novartis have longer contracts and are expected to work for at least 3 months. I would say that the majority of the interns that I met were doing 6 month internships. The demands of each group vary dramatically. Some interns had really light work loads on mundane projects and others had high workloads on important projects.\nIf your goal is to work at Novartis after finishing your internship know that you have to let your team know your goals. If you don’t tell them you want to work for Novartis you will never get hired. For me this was not an issue as I was not looking for a full-time job from Novartis after my internship."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#campus-life",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#campus-life",
    "title": "Inside a Basel Novartis Internship",
    "section": "Campus Life",
    "text": "Campus Life\nLife at Novartis campus is pretty awesome. They have a virtual tour available and if you are in Basel you can get an art tour of the campus. The architecture of the new buildings is really beautiful. There is a building designed by Frank Gehry. An overview of the other architecture can be found here. One of my favorite buildings was Asklepios, a new building overlooking the Rhine. The view from inside the building is fantastic. You can even take a swim in the Rhine during lunch.\n\n\n\nThe view from Asklepios of the Rhine\n\n\nThe campus is like a small city. You have a coop supermarket, many restaurants, coffee places (even starbucks), ice cream vendors, apple trees, koi pond, and lounge chairs. There is lots of trees and grass to have an enjoyable lunch. Coffee, tea and water are provided in the building. The free coffee is mediocre (the kaffee créme beans are better than the espresso roast) but you can always have a better cup of coffee at one of the cafés around campus.\n\n\n\nNice areas on campus to take a break\n\n\nThere are always interesting talks and presentations going on around campus. Biostatistics in particularly always seemed to have technical presentations going on. There is lots of effort put into professional development via presentations and courses. I attended a “biostatistics boot camp” which was one of my favorite parts of the summer. I highly recommend it to anyone interested in how drugs progress in human trials, from Phase 1 to market and beyond."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#pay-and-benefits",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#pay-and-benefits",
    "title": "Inside a Basel Novartis Internship",
    "section": "Pay and benefits",
    "text": "Pay and benefits\nThe base salary for a Master’s student is 2500 francs per month. There is also a living stipend of 600 francs per month. They provide one-way transportation fees up to 400 francs. Your salary is paid into a Novartis bank account where you can transfer money to EU banks. Interns receive vacation prorated for the amount of time they are staying based on the 5-week full time employee yearly vacation. For me this meant I had 5.5 days vacation. Depending on your contract you probably need to clock in your hours. This is done with your badge when you come into your building or go out for lunch. If you miss a clock-in there is an ancient web interface to do it on as well.\nNovartis has flexible working hours, which means that you are supposed to have within 25 hours of the monthly full time hours (40 hours per week). This means that if you work more than 8 hours in a day you accrue flextime, up to 25 hours. If you need to leave for a half-day you can take your flextime without any issue. I ended up accumulating lots of hours of flextime and was able to take three full days off in the middle of my internship to get a full week off due to a Thursday/Friday holiday for the Swiss National Day. I ended my internship with a huge surplus of flextime which I was told will be paid out. I did not end up taking my 5.5 days of vacation which will be paid out as well.\nIn general most people that I worked with were extremely busy and worked many hours. The older, more established employees seemed to take vacation regularly and it was common to have auto-reply emails for all of August. My building was a ghost town in August. Your work-life balance depends a lot on the group you are in. On average I worked about 46 hour weeks with the max being 57. I worked about two half days on the weekend but this was my choice to be better prepared for the week.\nYou are also allowed to work 20 percent from home (one full day a week). I didn’t really take advantage of this since I wanted to interact with as many people as I could."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#accomodations",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#accomodations",
    "title": "Inside a Basel Novartis Internship",
    "section": "Accomodations",
    "text": "Accomodations\nNovartis provides an options for housing through Aprentas housing. I stayed at the Eglisee Wohnheim Aprentas house which cost 700 francs per month for a “small” room. There are also larger rooms for 800 available. It is about 20–30 minutes by tram and about 35 minutes to walk. Biking is really fast if you have one. I ended up walking most days when it was not raining.\nIt was nice that I was able to move to Basel without having to worry about find a place to live. The house had capacity for 30 people, 15 guys and 15 girls. Almost everyone was an intern for Novartis which makes it easy to meet people. There was a shared kitchen and everyone had cleaning duty for a week at a time. Overall everyone was really nice and the staff took good care of the place. There was a large proportion of Italians in the house that seemed to always be cooking some amazing smelling food.\n\nWarning: Move in on the first or the sixteenth of the month\nOne gotcha with this was the first months rent (and potentially the last months as well). The housing provided charged full price if you moved in the first 15 days of the month and half price any of the second half days. Okay, seems reasonable. Novartis pro-rates the reimbursement amount based on exactly the number of days you worked this month. So if you move in on the first or 16, no problem. So if you move in the 15th, you will receive ~300 from Novartis but pay the full 700 amount. Similarly if you move in right before the end of the month you will be charged 300 and only receive a small stipend. I told Novartis HR about this but no policy change has occurred so make sure to confirm with them if you get an internship.\n\n\nWarning: Aprentas housing in Muttenz\nThere is a larger Aprentas housing in Muttenz. It is almost 45 minutes away from Novartis by tram and you are far out of the city center. For most people this housing option is probably worse. The benefits are it is really close to a bouldering gym, B2 Boulders and Bar as well as closer to the alps and popular tourist cities (Interlaken, Grindelwald, Bern, etc.)"
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#closing-thoughts",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#closing-thoughts",
    "title": "Inside a Basel Novartis Internship",
    "section": "Closing Thoughts",
    "text": "Closing Thoughts\nOverall I had an extremely positive internship experience with Novartis. I would highly recommend anyone interested in pharma to apply. It is a fast-paced environment that will challenge you and make you grow. I made so many good connections this summer and will definitely consider working their after I do my PhD. Feel free to reach out for any questions.\nIf you enjoyed this then stay tuned for my follow up on life in Basel, and the technical portions of my internship."
  },
  {
    "objectID": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#resources",
    "href": "posts/2019-09-01-inside-a-basel-novartis-internship/index.html#resources",
    "title": "Inside a Basel Novartis Internship",
    "section": "Resources",
    "text": "Resources\n\nNovartis Website\nNovartis LinkedIn\nNovartis Open Source\nAprentas Housing\nLife in Basel\nWork permits in Switzerland\nQuora: How can I win an internship at Roche or Novartis in Basel?"
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "",
    "text": "A cloze deletion test is a form of language test where a sentence (or paragraph) is given to the test taker with blanks for missing words [7]. The student is expected to fill in a “correct” word in the blanks.\nExample from Wikipedia’s article on cloze deletion [8]:\n\nToday, I went to the ____ and bought some milk and eggs.\n\nSome of the possible answers to fill in would be store, market, farm, etc.\nCloze deletion tests can be useful for language learners. These type of flashcards are described in great detail in Gabriel Wyner’s book, Fluent Forever [11]. The idea is to include a cloze deletion sentence, definition, a picture, other possibly relevant information (part of speech, conjugation, etc.). An example of these flash cards can be seen in Figure 1 on page .\n\nAfter using this method of studying for some time, I have found that certain sentences work better than other for remembering new vocabulary and grammar. Long sentences tended to be difficult to remember and were not as useful as I would tend to only look at a few words around the missing word. Cards that had a personal association were much easier to recall. Good definitions (simple and short but descriptive) helped as well.\nIn this paper I explore various machine learning approaches to predicting cloze deletion sentences from two Swedish news sources. The goals for this paper were to answer the following questions:\n\nCan we predict missing word using only the words around it?\nWhat sentences are good example sentences?\n\nDoes length of sentence make a difference?\n\nWhere are good sources to find cloze deletion sentences?\n\nI compare the difference between an LSTM (Long-Short term memory) neural network with that of a Bidirectional LSTM. Later the two news sources (described in Section 2) are compared to see which data set is easier to predict. Then I explore tuning the dropout parameter to see how overfitting can be improved. Finally the predictions are analyzed to see which sentences are easy to predict."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#data_processing",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#data_processing",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Creating Training Examples",
    "text": "Creating Training Examples\nEach sentence is divided into potentially many training examples. For each noun, adjective, or verb in a sentence a window around the word was selected. If we let define the window \\(k\\), and a sentence is defined as \\(s = (w_0,\\ldots, w_n)\\) where \\(w_i\\) is a word in the sentence (excluding punctuation). Then for a word \\(w_i\\), we use \\((w_{i-k},\\ldots,w_{i-1},w_{i+1},\\ldots,w_{i + k})\\) to try to predict \\(w_i\\). The before window is pre-padded with zeros when there are not three words found before the target word. The after window is post-padded with zeros. For all of the experiments a window size of 3 was used to predict the words."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#sec:model_config",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#sec:model_config",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Model Configuration",
    "text": "Model Configuration\nFor the first test, the 8 Sidor data set was used (number of sentences was \\(259,216\\).) A 30% validation set was used which resulted in \\(202,687\\) validation samples. Keras was used to implement the neural network [2]. A window size of 3 was used with \\(10,000\\) word limit on the vocabulary. Only verbs, adjectives, and nouns were used as the prediction word. Any word out of vocabulary was replaced with UNK, and if the out of vocabulary word was found in either the before window, the word, or the after window the training example was discarded. This resulted in \\(472,934\\) training examples.\n \nThe models were identical apart from the LSTM layer being bidirectional. The before window and after window are first concatenated into a single layer. Then an embedding layer is used with an embedding size of 100. The LSTM layer has 50 units, with the default Keras parameters of activation being \\(tanh\\). There is a dropout of \\(0.1\\) on both of the LSTM layers. The output layer has dimension \\(10,000 + 1\\) (the additional \\(+1\\) is to include the out of vocabulary token), with a softmax activation. The models were trained with the Adam optimizer with 30 epochs and batch size 64. The loss function is categorical cross entropy. The categorical cross entropy is a sum of each of the individual cross entropy results for each category [9]. \\[H(y, \\hat{y}) - \\frac{1}{n} \\sum_{i = 1}^{n} \\sum_{j = 1}^{m} y_{i,j} \\log(\\hat{y}_{i,j})\\] Where \\(y\\) is a vector of the true values, and \\(\\hat{y}\\) are our predictions. We define \\(n\\) as the number of examples, \\(m\\) as the number of categories and \\(y_{i,j}\\) as the \\(i\\)th example with category \\(j\\). We only have one non-zero value of \\(y_{i,j}\\) for each \\(i\\). So we can re-write this as \\[H(y, \\hat{y}) - \\frac{1}{n} \\sum_{i = 1}^{n} y_{i,c} \\log(\\hat{y}_{i,c})\\] where \\(c\\) is the only non-zero category for training example \\(i\\) since we do not have more than one category."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#results",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#results",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Results",
    "text": "Results\n\n\n\nComparing cross-entropy loss between LSTM and Bidirectional LSTM Models\n\n\n\n\n\nComparing accuracy loss between LSTM and Bidirectional LSTM Models\n\n\nWe can see the Bidirectional LSTM model performs much better than the LSTM model on the training data. It also performs a little bit better on the validation data. From these plots we can see that both the models are over fitting but the Bidirectional LSTM model is over fitting more so than the standard LSTM model."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#dropout-comparison",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#dropout-comparison",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Dropout Comparison",
    "text": "Dropout Comparison\n\n\n\nComparing dropout values of 0.2, 0.4, 0.6 and 0.8 on Bidirectional LSTM Model\n\n\nUsing the Bidirectional LSTM model described in the Model Config Section, an experiment was set up to see how dropout parameter affected the results on the model. All models has the Bidirectional LSTM Layer configured with the dropout set to the value \\(d = 0.2, 0.4, 0.6, 0.8\\). The models were all run with 25 epochs (\\(0,\\ldots,24\\)) that took about 300 seconds for each epoch. The recurrent dropout is also set to the same \\(d\\) value. As described in [3], the recurrent dropout randomly drops recurrent connection within the LSTM. The normal dropout parameter randomly drops the inputs and output into and out of the LSTM layer.\n\nComparing minimum loss across different dropout parameters\n\n\nDropout\nMinimum Loss\nMinimum Loss Epoch\n\n\n\n\n0.2\n3.374\n7\n\n\n0.4\n3.342\n23\n\n\n0.6\n3.451\n23\n\n\n0.8\n3.824\n24\n\n\n\nWe can see that with dropout set to \\(0.2\\), that the difference between the validation loss and the training loss is very high. The validation loss also starts to increase after epoch 7. The minimum value achieve was at epoch 7, with a categorical cross entropy of 3.374. For the other dropout values 0.4, 0.6, and 0.8 the minimum loss was 3.342, 3.451, and 3.824.\nWe can see as the dropout value increases, the training loss and validation loss are closer together, indicating less overfitting. When using a higher value of dropout, the model tends to converge slower. That is, we need more epochs to reach the same loss level. Both dropout of \\(0.6\\) and \\(0.8\\), but especially dropout of \\(0.8\\) could have been run for much longer to see where the loss converges to."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#best-prediction-examples",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#best-prediction-examples",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Best Prediction Examples",
    "text": "Best Prediction Examples\n\nBest prediction examples for 8 Sidor data set\n\n\n\n\n\n\nWord\nSentence\n\n\n\n\ninitiativ\nPartiet Feministiskt initiativ ställer upp i valet till EUs riksdag , Europaparlamentet .\n\n\neurovision\nSanna Nielsen från Sverige sjöng i musiktävlingen Eurovision Song Contest , ESC , på tisdagen .\n\n\nchampions\nMalmö FF förlorade även den andra matchen mot Juventus i Champions League i fotboll .\n\n\nfredspris\nLiu Xiaobo från Kina får Nobels fredspris i år .\n\n\neld\nMen muslimska ledare tror att någon tänt eld på huset .\n\n\ntv\nRättegången kommer att sändas i TV 4 plus .\n\n\nbin\nUsama bin Ladin är\n\n\nförenta\nFörenta Nationernas organisation Barnfonden säger att det finns sextusen barnsoldater i Sudan i Afrika .\n\n\ngreen\nHöjdhopparen Emma Green Tregaro har också en bra chans att ta medalj .\n\n\nsos\nEmil ringde till SOS Alarm för att bli hämtad av en ambulans .\n\n\nför\nCentrum för lättläst får pengar av staten för att göra det .\n\n\nvicepresident\nDet säger USAs vicepresident Joe Biden .\n\n\nreal\nKampen står mellan Ronaldo från Real Madrid och Lionel Messi eller Andres Iniesta från Barcelona , tror experterna .\n\n\ndaglig\nDaglig verksamhet är inte ett jobb som du får lön för att göra .\n\n\nröda\nMen nu stoppar både Röda Korset och FN hjälpen till de människor som är fast i Aleppo .\n\n\nfängelse\nHan är misstänkt för spioneri och kan dömas till livstids fängelse i USA .\n\n\nprocent\nBland eleverna är Miljöpartiet tredje största parti med nästan 15 procent av rösterna .\n\n\nmeter\nSusanna Kallur vann 100 meter häck vid en gala i Karlstad på onsdagen .\n\n\nbutikskedjan\nFabian Bengtsson är chef för butikskedjan Siba som säljer elektronik .\n\n\nalarm\nFöretaget SOS Alarm har fått hård kritik den senaste tiden .\n\n\n\nWe can see the predictions from the model which had the lowest cross entropy. Many of these top predicted words are parts of proper nouns or named entities which is fairly obvious because these words don’t appear in other contexts on their own.\nSome notable example from this list that would be good cloze deletion example are: initiativ, eld, fängelse, procent, meter.\n\nPartiet Feministiskt initiativ ställer upp i valet till EUs riksdag, Europaparlamentet.\nMen muslimska ledare tror att någon tänt eld på huset. (Good in the sense that goes together frequently)\nHan är misstänkt för spioneri och kan dömas till livstids fängelse i USA.\nBland eleverna är Miljöpartiet tredje största parti med nästan 15 procent av rösterna.\nSusanna Kallur vann 100 meter häck vid en gala i Karlstad på onsdagen.\n\nFor future work, removing these named entities would potentially be better for a language learner. We can also see from these example sentences that when named entities are found within the window that the predictions are very high. For example, for predicting initiativ, the proceeding words Partiet Feministiskt are likely not seen anywhere else in the data set. These type of examples can be good for a learner that has a connection in some way to Partiet Feministiskt, to learn the word for initiativ."
  },
  {
    "objectID": "posts/2018-11-05-cloze-deletion-detection/index.html#results-1",
    "href": "posts/2018-11-05-cloze-deletion-detection/index.html#results-1",
    "title": "Cloze Deletion Prediction with LSTM Neural Networks",
    "section": "Results",
    "text": "Results\n\n\n\nComparing accuracy and cross-entropy loss between 8 Sidor and GP 2013\n\n\n\n\n\nComparing accuracy and cross-entropy loss between 8 Sidor and GP 2013\n\n\nThe training loss decreasing fast for both data sets but the model overfits the training data. The loss for the Göteborgs-Posten data set actually starts to increase with the number of epochs. Overall, the model can predict better on the 8 Sidor data set than the data from Göteborgs-Posten 2013.\nThese results are consistent with the original hypothesis. 8 Sidor’s intention is to create simple to read new articles without complicated sentence structure and words. Often readers of this newspaper are learners of the Swedish language. Göteborgs-Posten wants to be interesting to its audience, which has presumably a majority native Swedish speakers. The writers want to write in an interesting way to convey a message with a much broader vocabulary. This can be seen in the part of speech count summary table."
  }
]